{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_model_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Swift",
      "language": "swift",
      "name": "swift"
    },
    "language_info": {
      "file_extension": ".swift",
      "mimetype": "text/x-swift",
      "name": "swift",
      "version": ""
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9TV7IYeqifSv"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors. [Licensed under the Apache License, Version 2.0](#scrollTo=ByZjmtFgB_Y5)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kZRlD4utdPuX",
        "colab": {}
      },
      "source": [
        "%install '.package(url: \"https://github.com/tensorflow/swift-models\", .branch(\"master\"))' Datasets ImageClassificationModels TrainingLoop\n",
        "print(\"\\u{001B}[2J\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tRIJp_4m_Afz",
        "colab": {}
      },
      "source": [
        "// #@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
        "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "// you may not use this file except in compliance with the License.\n",
        "// You may obtain a copy of the License at\n",
        "//\n",
        "// https://www.apache.org/licenses/LICENSE-2.0\n",
        "//\n",
        "// Unless required by applicable law or agreed to in writing, software\n",
        "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "// See the License for the specific language governing permissions and\n",
        "// limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sI1ZtrdiA4aY"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        " <td>\n",
        "  <a target=\"_blank\" href=\"https://www.tensorflow.org/swift/tutorials/simple_model_training\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        " </td>\n",
        " <td>\n",
        "  <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/swift/blob/master/docs/site/tutorials/simple_model_training.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        " </td>\n",
        " <td>\n",
        "  <a target=\"_blank\" href=\"https://github.com/tensorflow/swift/blob/master/docs/site/tutorials/simple_model_training.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        " </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rU0WY_sJodio"
      },
      "source": [
        "## Training an image classification model\n",
        "\n",
        "Let's take a look at how you'd set up and train an image classification model using the models, datasets, and general training loop provided by [the swift-models repository](https://github.com/tensorflow/swift-models).\n",
        "\n",
        "In this example, we'll be using the simple LeNet-5 model, the MNIST handwritten digit classification dataset, and a callback-based training loop.\n",
        "\n",
        "First, we'll import the necessary modules:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHRTNQJo1TxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Datasets\n",
        "import ImageClassificationModels\n",
        "import TensorFlow\n",
        "import TrainingLoop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbvY8dCzvUlo",
        "colab_type": "text"
      },
      "source": [
        "Then we'll specify the training parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FCMWR11NIIy-",
        "colab": {}
      },
      "source": [
        "let epochCount = 12\n",
        "let batchSize = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc2adjojvv00",
        "colab_type": "text"
      },
      "source": [
        "The training can either be performed using the default eager mode runtime, or the XLA-based X10 backend. For performance, and to support TPUs, we'll use an XLA-based X10 device:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qad9_yMYf6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// The following is a workaround needed until X10 can set log levels and memory growth parameters.\n",
        "let _ = _ExecutionContext.global\n",
        "\n",
        "let device = Device.defaultXLA\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXT4iwxOxCFZ",
        "colab_type": "text"
      },
      "source": [
        "Then we'll download and configure the MNIST dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcvQLqYMtCWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let dataset = MNIST(batchSize: batchSize, on: device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ5Hgk_YxKfC",
        "colab_type": "text"
      },
      "source": [
        "and the LeNet-5 model, along with an SGD optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jpcOByipc75O",
        "colab": {}
      },
      "source": [
        "var model = LeNet()\n",
        "var optimizer = SGD(for: model, learningRate: 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_TwGy2kxW-g",
        "colab_type": "text"
      },
      "source": [
        "The general-purpose training loop uses a callback mechanism to respond to actions and customize model training. In this example, we'll use an animated progress bar to display training status and simple statistics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De59VwJ35SvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let trainingProgress = TrainingProgress()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KVqnJaRxt74",
        "colab_type": "text"
      },
      "source": [
        "The training loop takes in the training and validation datasets, our optimizer, a loss function, and our custom callbacks. From these, it automatically handles the process of pulling epochs, shuffling batches, and placing the model and optimizer on the right device:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13AS_kR4vszR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var trainingLoop = TrainingLoop(\n",
        "  training: dataset.training,\n",
        "  validation: dataset.validation,\n",
        "  optimizer: optimizer,\n",
        "  lossFunction: softmaxCrossEntropy,\n",
        "  callbacks: [trainingProgress.update])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tVWWs7TyJa4",
        "colab_type": "text"
      },
      "source": [
        "Finally, we can train our model using the loop:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKH8_pi3yI_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try! trainingLoop.fit(&model, epochs: epochCount, on: device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwhDFzB0y3eh",
        "colab_type": "text"
      },
      "source": [
        "Note that loss decreases and accuracy increases over time for both training and validation, as we'd expect. If you executed this notebook on a GPU- or TPU-backed instance, the training should have run transparently on an accelerator.\n",
        "\n",
        "`model` now hosts parameters that have been trained against the MNIST dataset and can be used for additional work or serialized to disk."
      ]
    }
  ]
}